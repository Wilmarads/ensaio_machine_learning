# -*- coding: utf-8 -*-
"""DataMoney.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hzd8vBLlGz2gs7wq7ZL5oWxKQHvC90nF

# Libraries
"""

# from google.colab import drive
# drive.mount('/content/drive')

import pandas  as pd
import numpy   as np
import seaborn as sns
import math

from matplotlib        import pyplot                  as plt
from sklearn           import metrics                 as mt
from sklearn           import tree                    as tr
from sklearn           import linear_model            as lm
from sklearn           import cluster                 as ct

from sklearn.linear_model    import LogisticRegression, LinearRegression, ElasticNet
from sklearn.ensemble        import RandomForestClassifier, RandomForestRegressor
from sklearn.neighbors       import KNeighborsClassifier
from sklearn.tree            import DecisionTreeRegressor
from sklearn.preprocessing   import PolynomialFeatures
from sklearn.cluster         import KMeans, AffinityPropagation
from sklearn.metrics         import f1_score, auc, roc_curve, roc_auc_score, accuracy_score, recall_score, precision_score, r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, silhouette_score

"""# Classificação

## KNN

### 1.0 Training with performance evaluation by n_neighbors
"""

# Importing Dataset
X_train = pd.read_csv ('datasets/datasets_classificacao/X_training.csv') #/content/data_c
y_train = pd.read_csv ('datasets/datasets_classificacao/y_training.csv')
X_val = pd.read_csv ('datasets/datasets_classificacao/X_validation.csv')
y_val = pd.read_csv ('datasets/datasets_classificacao/y_validation.csv')
X_test = pd.read_csv ('datasets/datasets_classificacao/X_test.csv')
y_test = pd.read_csv ('datasets/datasets_classificacao/y_test.csv')

# Selected features
features = ['customer_type', 'age', 'class', 'flight_distance',
       'inflight_wifi_service', 'departure_arrival_time_convenient',
       'ease_of_online_booking', 'gate_location', 'food_and_drink',
       'online_boarding', 'seat_comfort', 'inflight_entertainment',
       'on_board_service', 'leg_room_service', 'baggage_handling',
       'checkin_service', 'inflight_service', 'cleanliness',
       'departure_delay_in_minutes', 'arrival_delay_in_minutes',
       'gender_Female', 'gender_Male', 'type_of_travel_business_travel'
]

label = [0]

x_train = X_train.loc[:, features]
y_train = y_train.iloc[:, 0]
x_val = X_test.loc[:, features]
y_val = y_val.iloc[:, 0]
x_test = X_test.loc[:, features]
y_test = y_test.iloc[:, 0]


#Training with performance evaluation by n_neighbors
k_list = np.arange (3,21)
accuracy_list = []

for i in k_list:
  print(f'K Number: {i}')
  knn_classifier = KNeighborsClassifier (n_neighbors=i)
  knn_classifier.fit (X_train, y_train)

  # Predict sobre os dados de treinamento
  yhat_train = knn_classifier.predict (X_train)
  # Metrics: Accuracy, Precision, Recall e F1-Score
  accuracy_train = mt.accuracy_score( y_train, yhat_train )
  print(f'Accuracy: {accuracy_train} \n')
  accuracy_list.append(accuracy_train)

"""### 1.1 Plot of train and test scores vs n_neighbors"""

## plot of train and test scores vs n_neighbors
plt.plot( k_list, accuracy_list, '-o', label='Validation' )
plt.legend()

plt.show()

"""### 1.2 Training models on all datasets"""

# Selecionado o K neighbors avaliar as métricas para todos os datasets

# Training model on training data
knn_classifier_train = KNeighborsClassifier(n_neighbors=5)
knn_classifier_train.fit(X_train, y_train)

# Prediction on training data
yhat_train = knn_classifier_train.predict (X_train)

# Metrics about training data
accuracy_train_knn = np.round( mt.accuracy_score (y_train, yhat_train) , 3)
prec_train_knn = np.round ( mt.precision_score(y_train, yhat_train), 3)
recall_train_knn = np.round( mt.recall_score (y_train, yhat_train), 3)
f1sc_train_knn = np.round( f1_score (y_train, yhat_train), 3)
print(f'Accuracy train: {accuracy_train_knn}, Precision train: {prec_train_knn}, Recall train: {recall_train_knn}, F1-Score train: {f1sc_train_knn} \n')


# Training model on validation data
knn_classifier_val = KNeighborsClassifier(n_neighbors=5)
knn_classifier_val.fit(X_train, y_train)

# Prediction on validation data
yhat_val = knn_classifier_val.predict (X_val)

# Metrics about validation data
accuracy_val_knn = np.round(mt.accuracy_score (y_val, yhat_val),3)
prec_val_knn = np.round (mt.precision_score(y_val, yhat_val),3)
recall_val_knn = np.round (mt.recall_score (y_val, yhat_val),3)
f1sc_val_knn = np.round(f1_score (y_val, yhat_val),3)
print(f'Accuracy val: {accuracy_val_knn}, Precision val: {prec_val_knn}, Recall val: {recall_val_knn}, F1-Score val: {f1sc_val_knn} \n')


# Model trained and validated with the Training dataset
knn_classifier_last = KNeighborsClassifier(n_neighbors=5)
knn_classifier_last.fit (np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))

# Prediction on test data
yhat_test = knn_classifier_last.predict (X_test)

# Metrics about test data
accuracy_test_knn = np.round(mt.accuracy_score ( y_test, yhat_test ),3)
prec_test_knn = np.round(mt.precision_score(y_test, yhat_test),3)
recall_test_knn = np.round(mt.recall_score (y_test, yhat_test),3)
f1sc_test_knn = np.round(f1_score (y_test, yhat_test),3)
print(f'Accuracy test: {accuracy_test_knn}, Precision test: {prec_test_knn}, Recall test: {recall_test_knn}, F1-Score test: {f1sc_test_knn} \n')

"""## Decision Tree

### 1.0 Training with performance evaluation by max_depth
"""

# Training with performance evaluation by max_depth
max_depth_list = np.arange (1, 60)
acc_list_tree = []

for i in max_depth_list:
  print(f'Max depth Number: {i}')
  model = tr.DecisionTreeClassifier (max_depth=i)
  model.fit (X_train, y_train)

  # Predict about training data
  yhat_val = model.predict (X_val)
  # Metrics
  acc_val = mt.accuracy_score( y_val, yhat_val )
  print(f'Accuracy: {acc_val} \n')
  acc_list_tree.append(acc_val)

"""### 1.1 Plot of train and test scores vs n_neighbors"""

# Plot of train and test scores vs n_neighbors
plt.plot( max_depth_list, acc_list_tree, '-o', label='max_depth' )
plt.legend()
plt.show()

"""### 1.2 Training models on all datasets"""

# Training models on all datasets

# Training model on training data
model_train = tr.DecisionTreeClassifier(max_depth=23)
model_train.fit(X_train, y_train)

# Prediction on training data
yhat_train = model_train.predict (X_train)

# Metrics about training data
acc_train_dt = np.round(mt.accuracy_score (y_train, yhat_train),3)
prec_train_dt = np.round(mt.precision_score(y_train, yhat_train),3)
recall_train_dt = np.round(mt.recall_score (y_train, yhat_train),3)
f1sc_train_dt = np.round(f1_score (y_train, yhat_train),3)
print(f'Accuracy train: {acc_train_dt}, Precision train: {prec_train_dt}, Recall train: {recall_train_dt}, F1-Score train: {f1sc_train_dt} \n')


# Training model on validation data
model_val = tr.DecisionTreeClassifier(max_depth=23)
model_val.fit(X_train, y_train)

# Prediction on validation data
yhat_val = model_val.predict (X_val)
# Metrics about training data
acc_val_dt = np.round(mt.accuracy_score (y_val, yhat_val),3)
prec_val_dt = np.round(mt.precision_score(y_val, yhat_val),3)
recall_val_dt = np.round(mt.recall_score (y_val, yhat_val),3)
f1sc_val_dt = np.round(f1_score (y_val, yhat_val),3)
print(f'Accuracy val: {acc_val_dt}, Precision val: {prec_val_dt}, Recall val: {recall_val_dt}, F1-Score val: {f1sc_val_dt} \n')

# Model trained and validated with the Training dataset
model_last = tr.DecisionTreeClassifier(max_depth=23)
model_last.fit (np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))

# Predict about test data
yhat_test = model_last.predict (X_test)

# Metrics about test data
acc_test_dt = np.round(mt.accuracy_score ( y_test, yhat_test ),3)
prec_test_dt = np.round(mt.precision_score(y_test, yhat_test),3)
recall_test_dt = np.round(mt.recall_score (y_test, yhat_test),3)
f1sc_test_dt = np.round(f1_score (y_test, yhat_test),3)
print(f'Accuracy test: {acc_test_dt}, Precision test: {prec_test_dt}, Recall test: {recall_test_dt}, F1-Score test: {f1sc_test_dt} \n')

"""## Random Forest

### 1.0 Importing Dataset
"""

# Importing Dataset
X_train = pd.read_csv ('datasets/datasets_classificacao/X_training.csv') #/content/data_c
y_train = pd.read_csv ('datasets/datasets_classificacao/y_training.csv')
X_val = pd.read_csv ('datasets/datasets_classificacao/X_validation.csv')
y_val = pd.read_csv ('datasets/datasets_classificacao/y_validation.csv')
X_test = pd.read_csv ('datasets/datasets_classificacao/X_test.csv')
y_test = pd.read_csv ('datasets/datasets_classificacao/y_test.csv')

"""### 1.1 Training with performance evaluation by max_depth"""

# Training with performance evaluation by max_depth

# Fit a model for max_depth variation
max_depth_list = np.arange(1,40)
best_threshold = []
accuracy_list = []

for i in max_depth_list:
  print(f"max_depth: {i}")
  forest = RandomForestClassifier(n_estimators=99, max_depth=i, random_state=0)
  forest.fit(X_train, y_train)

  # Predict about validation data
  y_scores = forest.predict_proba(X_val)[:, 1] # O 1 significa a coluna (classe) que se quer utilizar
  # Calculate ROC curve values
  fpr, tpr, thresholds = roc_curve(y_val, y_scores)
  # Calculate AUC score
  auc_score = roc_auc_score(y_val, y_scores)
  # Find the best threshold based on ROC curve
  distances = np.sqrt((1 - tpr)**2 + fpr**2) # distancia euclidiana de dois pontos. Usada, pois quero encontrar a distância da curva roc (na sua curva ) até o ponto 1 do tpr e ponto 0 do fpr
  best_threshold = thresholds[np.argmin(distances)]
  print(f"Best Threshold: {best_threshold}")
  # Calculate accuracy using the best threshold
  y_pred = (y_scores >= best_threshold).astype(int)
  accuracy = accuracy_score(y_val, y_pred)
  print(f"Accuracy: {accuracy}")

"""### 1.2 Fit a model for n_estimator variation and maxdepth = 20"""

# Fit a model for n_estimator variation and maxdepth = 20
n_estimators_list = np.arange(90,100)
best_threshold = []
accuracy_list = []

for i in n_estimators_list:
  print(f"n_estimatros: {i}")
  model = RandomForestClassifier(n_estimators=i, max_depth=20, random_state=0)
  model.fit(X_train, y_train)

  # Predict
  y_scores = model.predict_proba(X_val)[:, 1] # O 1 significa a coluna (classe) que se quer utilizar
  # Calculate ROC curve values
  fpr, tpr, thresholds = roc_curve(y_val, y_scores)
  # Calculate AUC score
  auc_score = roc_auc_score(y_val, y_scores)
  # Find the best threshold based on ROC curve
  distances = np.sqrt((1 - tpr)**2 + fpr**2) # distancia euclidiana de dois pontos. Usada, pois quero encontrar a distância da curva roc (na sua curva ) até o ponto 1 do tpr e ponto 0 do fpr
  best_threshold = thresholds[np.argmin(distances)]
  print(f"Best Threshold: {best_threshold}")
  # Calculate accuracy using the best threshold
  y_pred = (y_scores >= best_threshold).astype(int)
  accuracy = accuracy_score(y_val, y_pred)
  print(f"Accuracy: {accuracy}")

"""### 1.3 Fit a model for the best n_estimators and maxdepth parameters"""

# Fit a model for the best n_estimators and maxdepth parameters


# Fit about training data
forest = RandomForestClassifier(n_estimators=99, max_depth=33, random_state=0)
forest.fit(X_train, y_train)

# Predict about data training
y_scores = forest.predict_proba(X_train)[:, 1] # O 1 significa a coluna (classe) que se quer utilizar
# Calculate ROC curve values
fpr, tpr, thresholds = roc_curve(y_train, y_scores)
# Calculate AUC score
auc_score = roc_auc_score(y_train, y_scores)
# Find the best threshold based on ROC curve
distances = np.round(np.sqrt((1 - tpr)**2 + fpr**2),3) # distancia euclidiana de dois pontos. Usada, pois quero encontrar a distância da curva roc (na sua curva ) até o ponto 1 do tpr e ponto 0 do fpr
best_threshold = np.round(thresholds[np.argmin(distances)],3)
print(f"Best Threshold: {best_threshold}")
# Calculate accuracy using the best threshold
y_pred = (y_scores >= best_threshold).astype(int)
accuracy_train_rf = np.round(accuracy_score(y_train, y_pred),3)
precision_train_rf = np.round(precision_score (y_train, y_pred),3)
recall_train_rf = np.round(recall_score (y_train, y_pred),3)
f1score_train_rf = np.round(f1_score (y_train, y_pred),3)
print(f"Accuracy_train: {accuracy_train_rf}, Precision_train: {precision_train_rf}, Recall_train: {recall_train_rf}, F1-Score_train:{f1score_train_rf}")


# Training about training data
forest = RandomForestClassifier(n_estimators=99, max_depth=33, random_state=0)
forest.fit(X_train, y_train)

# Predict about validation data
y_scores = forest.predict_proba(X_val)[:, 1] # O 1 significa a coluna (classe) que se quer utilizar
# Calculate ROC curve values
fpr, tpr, thresholds = roc_curve(y_val, y_scores)
# Calculate AUC score
auc_score = roc_auc_score(y_val, y_scores)
# Find the best threshold based on ROC curve
distances = np.round(np.sqrt((1 - tpr)**2 + fpr**2),3) # distancia euclidiana de dois pontos. Usada, pois quero encontrar a distância da curva roc (na sua curva ) até o ponto 1 do tpr e ponto 0 do fpr
best_threshold = np.round(thresholds[np.argmin(distances)],3)
print(f"Best Threshold: {best_threshold}")
# Calculate accuracy using the best threshold
y_pred = (y_scores >= best_threshold).astype(int)
accuracy_val_rf = np.round(accuracy_score(y_val, y_pred),3)
precision_val_rf = np.round(precision_score (y_val, y_pred),3)
recall_val_rf = np.round(recall_score (y_val, y_pred),3)
f1score_val_rf = np.round(f1_score (y_val, y_pred),3)
print(f"Accuracy_val: {accuracy_val_rf}, Precision_val: {precision_val_rf}, Recall_va: {recall_val_rf}, F1-Score_val:{f1score_val_rf}")

## Model trained and validated with the Training dataset
forest_last = RandomForestClassifier( n_estimators=99, max_depth=33, random_state=0)
forest_last.fit (np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))

# Predict about test data
y_scores = forest_last.predict_proba(X_test)[:, 1] # O 1 significa a coluna (classe) que se quer utilizar
# Calculate ROC curve values
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
# Calculate AUC score
auc_score = roc_auc_score(y_test, y_scores)
# Find the best threshold based on ROC curve
distances = np.round(np.sqrt((1 - tpr)**2 + fpr**2),3) # distancia euclidiana de dois pontos. Usada, pois quero encontrar a distância da curva roc (na sua curva ) até o ponto 1 do tpr e ponto 0 do fpr
best_threshold = np.round(thresholds[np.argmin(distances)],3)
print(f"Best Threshold: {best_threshold}")
# Calculate accuracy using the best threshold
y_pred = (y_scores >= best_threshold).astype(int)
accuracy_test_rf = np.round(accuracy_score(y_test, y_pred),3)
precision_test_rf = np.round(precision_score (y_test, y_pred),3)
recall_test_rf = np.round(recall_score (y_test, y_pred),3)
f1score_test_rf = np.round(f1_score (y_test, y_pred),3)
print(f"Accuracy_test: {accuracy_test_rf}, Precision_test: {precision_test_rf}, Recall_test: {recall_test_rf}, F1-Score_test:{f1score_test_rf}")

"""## Regressão Logistica

### 1.0 Instantiating the Logistic Regression model
"""

# Instantiating the Logistic Regression model

max_iter_list = np.arange(50,100)
maxiter = []

for i in max_iter_list:
  print(f"number max iter: {i}")
  model = LogisticRegression(C=0.5, max_iter=i , solver='lbfgs')
  # Training model
  model.fit(X_train, y_train)
  # Predict about validation data
  yhat_val = model.predict( X_val )
  acc = accuracy_score (y_val, yhat_val)
  # prec = precision_score (y_val, yhat_val)
  # rec = recall_score (y_val, yhat_val)
  # f1 = mt.f1_score( y_val, yhat_val )
  print('Accuracy_val: {:.3f}'.format( acc ))

"""### 1.1 Instantiating the Logistic Regression model with the max_iter and C parameters defined"""

# Instantiating the Logistic Regression model with the max_iter and C parameters defined
model = LogisticRegression(C=0.2, max_iter=50, solver='lbfgs')

# Training model Logistic Regression
model.fit(X_train, y_train)

# Predict about training data
yhat_train = model.predict( X_train )

# Metrics
acc_train_lr = np.round(accuracy_score (y_train, yhat_train),3)
prec_train_lr = np.round(precision_score (y_train, yhat_train),3)
rec_train_lr = np.round(recall_score (y_train, yhat_train),3)
f1_train_lr = np.round(mt.f1_score(y_train, yhat_train),3)
print('Accuracy_train: {:.3f}'.format( acc_train_lr ), 'Precision_train: {:.3f}'.format (prec_train_lr), 'Recall_train: {:.3f}'.format (rec_train_lr), 'F1-Score_train: {:.3f}'.format (f1_train_lr)  )

# Predict about validation data
yhat_val = model.predict( X_val )

# Metrics
acc_val_lr = np.round(accuracy_score (y_val, yhat_val),3)
prec_val_lr = np.round(precision_score (y_val, yhat_val),3)
rec_val_lr = np.round(recall_score (y_val, yhat_val),3)
f1_val_lr = np.round(mt.f1_score( y_val, yhat_val ),3)
print('Accuracy_val: {:.3f}'.format( acc_val_lr ), 'Precision_val: {:.3f}'.format (prec_val_lr), 'Recall_val: {:.3f}'.format (rec_val_lr), 'F1-Score_val: {:.3f}'.format (f1_val_lr)  )

# Concatenat datase train and val
model_last_LR = LogisticRegression(C=0.2, max_iter=50, solver='newton-cg')
model_last_LR.fit (np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))

# Predict about test data
yhat_test = model_last_LR.predict( X_test )

# Metrics
acc_test_lr = np.round(accuracy_score (y_test, yhat_test),3)
prec_test_lr = np.round(precision_score (y_test, yhat_test),3)
rec_test_lr = np.round(recall_score (y_test, yhat_test),3)
f1_test_lr = np.round(mt.f1_score(y_test, yhat_test),3)
print('Accuracy_test: {:.3f}'.format( acc_test_lr ), 'Precision_test: {:.3f}'.format (prec_test_lr), 'Recall_test: {:.3f}'.format (rec_test_lr), 'F1-Score_test: {:.3f}'.format (acc_test_lr)  )

"""## Resultados Classificação


"""

# Defining lists to store training data
models = ['KNN',  'Decision Tree' , 'Random Forest' , 'Logistic Regression']
accuracy_train = [accuracy_train_knn, acc_train_dt, accuracy_train_rf, acc_train_lr ]
precision_train = [prec_train_knn, prec_train_dt, precision_train_rf, prec_train_lr]
recall_train = [recall_train_knn, recall_train_dt, recall_train_rf, rec_train_lr]
f1_score_train = [f1sc_train_knn, f1sc_train_dt,f1score_train_rf, f1_train_lr ]

# Defining lists to store validation data
models = ['KNN',  'Decision Tree' , 'Random Forest' , 'Logistic Regression']
accuracy_val = [accuracy_val_knn, acc_val_dt, accuracy_val_rf, acc_val_lr ]
precision_val = [prec_val_knn, prec_val_dt, precision_val_rf, prec_val_lr ]
recall_val = [recall_val_knn, recall_val_dt, recall_val_rf, rec_val_lr ]
f1_score_val = [f1sc_val_knn, f1sc_val_dt, f1score_val_rf, f1_val_lr ]

# Defining lists to store teste data
models = ['KNN',  'Decision Tree' , 'Random Forest' , 'Logistic Regression']
accuracy_test = [accuracy_test_knn, acc_test_dt, accuracy_test_rf, acc_test_lr ]
precision_test = [prec_test_knn, prec_test_dt, precision_test_rf, prec_test_lr]
recall_test = [recall_test_knn, recall_test_dt, recall_test_rf, rec_test_lr ]
f1_score_test = [f1sc_test_knn, f1sc_test_dt, f1score_test_rf, f1_test_lr ]


# Creating dictionaries
data_train = {'Model': models, 'Accuracy': accuracy_train, 'Precision': precision_train, 'Recall': recall_train, 'F1-Score': f1_score_train}
data_val = {'Model': models, 'Accuracy': accuracy_val, 'Precision': precision_val, 'Recall': recall_val, 'F1-Score': f1_score_val}
data_test = {'Model': models, 'Accuracy': accuracy_test, 'Precision': precision_test, 'Recall': recall_test, 'F1-Score': f1_score_test}

# Creating Dataframes with the results
df_train = pd.DataFrame(data_train)
df_val = pd.DataFrame(data_val)
df_test = pd.DataFrame(data_test)

df_train

df_val

df_test

"""# Regressão"""

# Importing dataset
X_train = pd.read_csv ('datasets/datasets_regressao/X_training.csv')
y_train = pd.read_csv ('datasets/datasets_regressao/y_training.csv')
X_val = pd.read_csv ('datasets/datasets_regressao/X_validation.csv')
y_val = pd.read_csv ('datasets/datasets_regressao/y_val.csv')
X_test = pd.read_csv ('datasets/datasets_regressao/X_test.csv')
y_test = pd.read_csv ('datasets/datasets_regressao/y_test.csv')

"""## Decision Tree Regression"""

# Testing performance according to variation of max_depth
max_depth_list = np.arange (1, 30)
r2_list = []

for i in max_depth_list:
  print(f'Max depth Number: {i}')
  dtregressor = DecisionTreeRegressor (max_depth=i)
  dtregressor.fit (X_train, y_train)

  # Predict about training data
  yhat_val = dtregressor.predict (X_val)
  # Metrics
  r2_val = r2_score( y_val, yhat_val )
  print(f'R2: {r2_val} \n')
  r2_list.append(r2_val)

# Plot of train and test scores vs n_neighbors
plt.plot( max_depth_list, r2_list, '-o', label='max_depth' )
plt.legend()
plt.show()

# Performance with max_depth 19
dtregressor = DecisionTreeRegressor (max_depth=19)
dtregressor.fit (X_train, y_train)

# Predict Predict about training data
yhat_train = dtregressor.predict (X_train)
# Metrics
r2_train_dt = np.round(r2_score( y_train, yhat_train ), 3)
mse_train_dt = np.round (mean_squared_error( y_train, yhat_train ) ,3 )
rmse_train_dt = np.sqrt (mse_train_dt)
mae_train_dt = mean_absolute_error (y_train, yhat_train)
mape_train_dt = np.round (mean_absolute_percentage_error ( y_train, yhat_train ) , 3)
print(f'R2 train: {r2_train_dt} \n', f'MSE train: {mse_train_dt} \n', f'RMSE train: {rmse_train_dt} \n', f'MAE train: {mae_train_dt} \n', f'MAPE train: {mape_train_dt} \n')

# Predict about validation data
yhat_val = dtregressor.predict (X_val)
# Metrics
r2_val_dt = np.round(r2_score( y_val, yhat_val ), 3)
mse_val_dt = np.round (mean_squared_error( y_val, yhat_val ) ,3 )
rmse_val_dt = np.sqrt (mse_val_dt)
mae_val_dt = mean_absolute_error (y_val, yhat_val)
mape_val_dt = np.round (mean_absolute_percentage_error ( y_val, yhat_val ) , 3)
print(f'R2 val: {r2_val_dt} \n', f'MSE val: {mse_val_dt} \n', f'RMSE val: {rmse_val_dt} \n', f'MAE val: {mae_val_dt} \n', f'MAPE: {mape_val_dt} \n')

# Concatenat datase train and val
dtregressor_last = DecisionTreeRegressor(max_depth=19)
dtregressor_last.fit (np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))

# Predict about test data
yhat_test = dtregressor.predict (X_test)
# Metrics
r2_test_dt = np.round(r2_score( y_test, yhat_test ), 3)
mse_test_dt = np.round (mean_squared_error( y_test, yhat_test ) ,3 )
rmse_test_dt = np.sqrt (mse_test_dt)
mae_test_dt = mean_absolute_error (y_test, yhat_test)
mape_test_dt = np.round (mean_absolute_percentage_error ( y_test, yhat_test ) , 3)
print(f'Dados de test R2: {r2_test_dt} \n', f'MSE: {mse_test_dt} \n', f'RMSE: {rmse_test_dt} \n', f'MAE: {mae_test_dt} \n', f'MAPE: {mape_test_dt} \n')



"""## Random Forest Regressor"""

# Testing performance according to variation of max_depth
max_depth_list = np.arange(1,50)
r2_list = []

# Training model to variation of max_depth
for i in max_depth_list:
  print(f'Max depth Number: {i}')
  # Treinando o modelo
  random_regre = RandomForestRegressor (max_depth= i, n_estimators= 100)
  random_regre.fit (X_train, y_train)
  # Predict about training data
  yhat_train = random_regre.predict(X_train)
  #Metrics
  r2_train = np.round (r2_score (y_train, yhat_train),3)
  print(f'R2 train: {r2_train}')

# Training model performance with max_depth 31
random_regre = RandomForestRegressor (max_depth= 31, n_estimators= 100)
random_regre.fit (X_train, y_train)

# Predict about training data
yhat_train = random_regre.predict(X_train)
# Metrics
r2_train_rf = np.round (r2_score (y_train, yhat_train),3)
mse_train_rf = np.round ((mean_squared_error(y_train, yhat_train)),3)
rmse_train_rf = np.round(np.sqrt(mse_train_rf),3)
mae_train_rf = np.round(mean_absolute_error (y_train, yhat_train),3)
mape_train_rf = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_rf}, MSE train: {mse_train_rf}, RMSE train: {rmse_train_rf}, MAE train: {mae_train_rf}, MAPE train: {mape_train_rf}')

# Predict about validation train
yhat_val = random_regre.predict(X_val)
# Metrics
r2_val_rf = np.round (r2_score (y_val, yhat_val),3)
mse_val_rf = np.round ((mean_squared_error(y_val, yhat_val)),3)
rmse_val_rf = np.round(np.sqrt(mse_val_rf),3)
mae_val_rf = np.round(mean_absolute_error (y_val, yhat_val),3)
mape_val_rf = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_rf}, MSE val: {mse_val_rf}, RMSE val: {rmse_val_rf}, MAE val: {mae_val_rf}, MAPE val: {mape_val_rf}')

# Training the model on conatenated training and validation data
random_regre_last = RandomForestRegressor (n_estimators=100, max_depth=31)
random_regre_last.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))

# Predict about test validation
yhat_test = random_regre_last.predict(X_test)
# Metrics
r2_test_rf = np.round (r2_score (y_test, yhat_test),3)
mse_test_rf = np.round ((mean_squared_error(y_test, yhat_test)),3)
rmse_test_rf = np.round(np.sqrt(mse_test_rf),3)
mae_test_rf = np.round(mean_absolute_error (y_test, yhat_test),3)
mape_test_rf = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 teste: {r2_test_rf}, MSE teste: {mse_test_rf}, RMSE teste: {rmse_test_rf}, MAE teste: {mae_test_rf}, MAPE teste: {mape_test_rf}')

"""## Polinomial Regression"""

# Training model training data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features = poly.fit_transform(X_train)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features, y_train)

# Predict about training data
yhat_train = poly_reg_model.predict(poly_features)

# Metrics
r2_train_pr = np.round (r2_score (y_train, yhat_train),3)
mse_train_pr = np.round (mean_squared_error(y_train, yhat_train), 3)
rmse_train_pr = np.round(np.sqrt(mse_train_pr),3)
mae_train_pr = np.round(mean_absolute_error(y_train, yhat_train),3)
mape_train_pr = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_pr}, MSE train: {mse_train_pr}, RMSE train: {rmse_train_pr}, MAE train: {mae_train_pr}, MAPE train: {mape_train_pr}')

# Training model validation data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features_val = poly.fit_transform(X_val)
poly_reg_model_val = LinearRegression ()
poly_reg_model_val.fit(poly_features_val, y_val)

# Predict about validation data
yhat_val = poly_reg_model_val.predict(poly_features_val)

# Metrics
r2_val_pr = np.round (r2_score (y_val, yhat_val),3)
mse_val_pr = np.round (mean_squared_error(y_val, yhat_val), 3)
rmse_val_pr = np.round(np.sqrt(mse_val_pr),3)
mae_val_pr = np.round(mean_absolute_error(y_val, yhat_val),3)
mape_val_pr = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_pr}, MSE val: {mse_val_pr}, RMSE val: {rmse_val_pr}, MAE val: {mae_val_pr}, MAPE val: {mape_val_pr}')

# Training model test data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features_test = poly.fit_transform(X_test)
poly_reg_model_test = LinearRegression ()
poly_reg_model_test.fit(poly_features_test, y_test)

# Predict about test data
yhat_test = poly_reg_model_test.predict(poly_features_test)

#Metrics
r2_test_pr = np.round (r2_score (y_test, yhat_test),3)
mse_test_pr = np.round (mean_squared_error(y_test, yhat_test), 3)
rmse_test_pr = np.round(np.sqrt(mse_test_pr),3)
mae_test_pr = np.round(mean_absolute_error(y_test, yhat_test),3)
mape_test_pr = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 test: {r2_test_pr}, MSE test: {mse_test_pr}, RMSE test: {rmse_test_pr}, MAE test: {mae_test_pr}, MAPE test: {mape_test_pr}')

"""## Polinomial Regression Lasso"""

# Training model training data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features = poly.fit_transform(X_train)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features, y_train)

# Lasso
lasso = lm.Lasso( alpha=2, max_iter=1000 )
lasso.fit(poly_features, y_train)

# Predict about training data
yhat_train = lasso.predict(poly_features)

# Metrics
r2_train_prl = np.round (r2_score (y_train, yhat_train),3)
mse_train_prl = np.round (mean_squared_error(y_train, yhat_train), 3)
rmse_train_prl = np.round(np.sqrt(mse_train_prl),3)
mae_train_prl = np.round(mean_absolute_error(y_train, yhat_train),3)
mape_train_prl = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_prl}, MSE train: {mse_train_prl}, RMSE train: {rmse_train_prl}, MAE train: {mae_train_prl}, MAPE train: {mape_train_prl}')

# Training model validation data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features_val = poly.fit_transform(X_val)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features_val, y_val)

# Lasso
lasso_val = lm.Lasso( alpha=2, max_iter=1000 )
lasso_val.fit(poly_features_val, y_val)

# Predict about validation data
yhat_val = lasso_val.predict(poly_features_val)

# Metrics
r2_val_prl = np.round (r2_score (y_val, yhat_val),3)
mse_val_prl = np.round (mean_squared_error(y_val, yhat_val), 3)
rmse_val_prl = np.round(np.sqrt(mse_val_prl),3)
mae_val_prl = np.round(mean_absolute_error(y_val, yhat_val),3)
mape_val_prl = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_prl}, MSE val: {rmse_val_prl}, RMSE val: {rmse_val_prl}, MAE val: {mae_val_prl}, MAPE val: {mape_val_prl}')

# Training model test data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features_test = poly.fit_transform(X_test)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features_test, y_test)

# Lasso
lasso_test = lm.Lasso( alpha=2, max_iter=1000 )
lasso_test.fit(poly_features_test, y_test)

# Predict about test data
yhat_test = lasso_test.predict(poly_features_test)

# Metrics
r2_test_prl = np.round (r2_score (y_test, yhat_test),3)
mse_test_prl = np.round (mean_squared_error(y_test, yhat_test), 3)
rmse_test_prl = np.round(np.sqrt(mse_test_prl),3)
mae_test_prl = np.round(mean_absolute_error(y_test, yhat_test),3)
mape_test_prl = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 test: {r2_test_prl}, MSE test: {mse_test_prl}, RMSE test: {rmse_test_prl}, MAE test: {mae_test_prl}, MAPE test: {mape_test_prl}')

"""## Polinomial Regression Ridge"""

# Treining model training data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features = poly.fit_transform(X_train)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features, y_train)

# Ridge
ridge = lm.Ridge( alpha=2, max_iter=1000 )
ridge.fit(poly_features, y_train)

# Predict about training data
yhat_train = ridge.predict(poly_features)

# Metrics
r2_train_prr = np.round (r2_score (y_train, yhat_train),3)
mse_train_prr = np.round (mean_squared_error(y_train, yhat_train), 3)
rmse_train_prr = np.round(np.sqrt(mse_train_prr),3)
mae_train_prr = np.round(mean_absolute_error(y_train, yhat_train),3)
mape_train_prr = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_prr}, MSE train: {mse_train_prr}, RMSE train: {rmse_train_prr}, MAE train: {mae_train_prr}, MAPE train: {mape_train_prr}')

# Treining model validation data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features_val = poly.fit_transform(X_val)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features_val, y_val)

# Ridge
ridge_val = lm.Ridge( alpha=2, max_iter=1000 )
ridge_val.fit(poly_features_val, y_val)

# Predict about validation data
yhat_val = ridge_val.predict(poly_features_val)

# Metrics
r2_val_prr = np.round (r2_score (y_val, yhat_val),3)
mse_val_prr = np.round (mean_squared_error(y_val, yhat_val), 3)
rmse_val_prr = np.round(np.sqrt(mse_val_prr),3)
mae_val_prr = np.round(mean_absolute_error(y_val, yhat_val),3)
mape_val_prr = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_prr}, MSE val: {mse_val_prr}, RMSE val: {rmse_val_prr}, MAE val: {mae_val_prr}, MAPE val: {mape_val_prr}')

# Treining model test data
poly = PolynomialFeatures (degree=2, include_bias=False)
poly_features_test = poly.fit_transform(X_test)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features_test, y_test)

# Ridge
ridge_test = lm.Ridge( alpha=2, max_iter=1000 )
ridge_test.fit(poly_features_test, y_test)

# Predict about test data
yhat_test = ridge_test.predict(poly_features_test)

# Metrics
r2_test_prr = np.round (r2_score (y_test, yhat_test),3)
mse_test_prr = np.round (mean_squared_error(y_test, yhat_test), 3)
rmse_test_prr = np.round(np.sqrt(mse_test_prr),3)
mae_test_prr = np.round(mean_absolute_error(y_test, yhat_test),3)
mape_test_prr = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 test: {r2_test_prr}, MSE test: {mse_test_prr}, RMSE test: {rmse_test_prr}, MAE test: {mae_test_prr}, MAPE test: {mape_test_prr}')

"""## Polinomial Regression Elastic Net"""

# Training model traning data
poly = PolynomialFeatures (degree=1, include_bias=False)
poly_features = poly.fit_transform(X_train)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features, y_train)

# ElasticNet
elastic = lm.ElasticNet( alpha=2, max_iter=1000, l1_ratio=0.5 )
elastic.fit(poly_features, y_train)

# Predict about trainin data
yhat_train = elastic.predict(X_train)

# Metrics
r2_train_pren = np.round (r2_score (y_train, yhat_train),3)
mse_train_pren = np.round (mean_squared_error(y_train, yhat_train), 3)
rmse_train_pren = np.round(np.sqrt(mse_train_pren),3)
mae_train_pren = np.round(mean_absolute_error(y_train, yhat_train),3)
mape_train_pren = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_pren}, MSE train: {mse_train_pren}, RMSE train: {rmse_train_pren}, MAE train: {mae_train_pren}, MAPE train: {mape_train_pren}')

# Training model traning data
poly = PolynomialFeatures (degree=1, include_bias=False)
poly_features_val = poly.fit_transform(X_val)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features_val, y_val)

# ElasticNet
elastic_val = lm.ElasticNet( alpha=2, max_iter=1000, l1_ratio=0.5 )
elastic_val.fit(poly_features_val, y_val)

# Predict about validation data
yhat_val = elastic_val.predict(X_val)

# Metrics
r2_val_pren = np.round (r2_score (y_val, yhat_val),3)
mse_val_pren = np.round (mean_squared_error(y_val, yhat_val), 3)
rmse_val_pren = np.round(np.sqrt(mse_val_pren),3)
mae_val_pren = np.round(mean_absolute_error(y_val, yhat_val),3)
mape_val_pren = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_pren}, MSE val: {mse_val_pren}, RMSE val: {rmse_val_pren}, MAE val: {mae_val_pren}, MAPE val: {mape_val_pren}')

# Training model traning data
poly = PolynomialFeatures (degree=1, include_bias=False)
poly_features_test = poly.fit_transform(X_test)
poly_reg_model = LinearRegression ()
poly_reg_model.fit(poly_features_test, y_test)

# ElasticNet
elastic_test = lm.ElasticNet( alpha=2, max_iter=1000, l1_ratio=0.5 )
elastic_test.fit(poly_features_test, y_test)

# Predict about test data
yhat_test = elastic_test.predict(X_test)

# Metrics
r2_test_pren = np.round (r2_score (y_test, yhat_test),3)
mse_test_pren = np.round (mean_squared_error(y_test, yhat_test), 3)
rmse_test_pren = np.round(np.sqrt(mse_test_pren),3)
mae_test_pren = np.round(mean_absolute_error(y_test, yhat_test),3)
mape_test_pren = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 test: {r2_test_pren}, MSE test: {mse_test_pren}, RMSE test: {rmse_test_pren}, MAE test: {mae_test_pren}, MAPE test: {mape_test_pren}')

"""## Linear Regresssion"""

# Training model training data
linear_regre = LinearRegression ()
linear_regre.fit(X_train, y_train)


# Predict about training data
yhat_train = linear_regre.predict(X_train)

# Metrics
r2_train_lr = np.round (r2_score (y_train, yhat_train),3)
mse_train_lr = np.round (mean_squared_error(y_train, yhat_train), 3)
rmse_train_lr = np.round(np.sqrt(mse_train_lr),3)
mae_train_lr = np.round(mean_absolute_error(y_train, yhat_train),3)
mape_train_lr = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_lr}, MSE train: {mse_train_lr}, RMSE train: {rmse_train_lr}, MAE train: {mae_train_lr}, MAPE train: {mape_train_lr}')

# Predict sobre os dados de validação
yhat_val = linear_regre.predict(X_val)

# Metrics
r2_val_lr = np.round (r2_score (y_val, yhat_val),3)
mse_val_lr = np.round (mean_squared_error(y_val, yhat_val), 3)
rmse_val_lr = np.round(np.sqrt(mse_val_lr),3)
mae_val_lr = np.round(mean_absolute_error(y_val, yhat_val),3)
mape_val_lr = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_lr}, MSE val: {mse_val_lr}, RMSE val: {rmse_val_lr}, MAE val: {mae_val_lr}, MAPE val: {mape_val_lr}')

# Training the model on conatenated training and validation data
linear_regre_last = LinearRegression ()
linear_regre_last.fit(np.concatenate((X_train, X_val )), np.concatenate((y_train, y_val)))

# Predict about test data
yhat_test = linear_regre_last.predict(X_test)

# Metrics
r2_test_lr = np.round (r2_score (y_test, yhat_test),3)
mse_test_lr = np.round (mean_squared_error(y_test, yhat_test), 3)
rmse_test_lr = np.round(np.sqrt(mse_test_lr),3)
mae_test_lr = np.round(mean_absolute_error(y_test, yhat_test),3)
mape_test_lr = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 test: {r2_test_lr}, MSE test: {mse_test_lr}, RMSE test: {rmse_test_lr}, MAE test: {mae_test_lr}, MAPE test: {mape_test_lr}')

"""## Linear Regression Lasso"""

# Training the model on training data
linear_regre = LinearRegression ()
linear_regre.fit(X_train, y_train)

lasso = lm.Lasso(alpha=2, max_iter=1000)
lasso.fit(X_train, y_train)

# Predict about training data
yhat_train = lasso.predict(X_train)

# Metrics
r2_train_lrl = np.round (r2_score (y_train, yhat_train),3)
mse_train_lrl = np.round (mean_squared_error(y_train, yhat_train), 3)
rmse_train_lrl = np.round(np.sqrt(mse_train_lrl),3)
mae_train_lrl = np.round(mean_absolute_error(y_train, yhat_train),3)
mape_train_lrl = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_lrl}, MSE train: {mse_train_lrl}, RMSE train: {rmse_train_lrl}, MAE train: {mae_train_lrl}, MAPE train: {mape_train_lrl}')

# Predict about validation data
yhat_val = lasso.predict(X_val)

# Metrics
r2_val_lrl = np.round (r2_score (y_val, yhat_val),3)
mse_val_lrl = np.round (mean_squared_error(y_val, yhat_val), 3)
rmse_val_lrl = np.round(np.sqrt(mse_val_lrl),3)
mae_val_lrl = np.round(mean_absolute_error(y_val, yhat_val),3)
mape_val_lrl = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_lrl}, MSE val: {mse_val_lrl}, RMSE val: {rmse_val_lrl}, MAE val: {mae_val_lrl}, MAPE val: {mape_val_lrl}')

# Training the model on conatenated training and validation data
linear_regre_last = LinearRegression ()
linear_regre_last.fit(np.concatenate((X_train, X_val )), np.concatenate((y_train, y_val)))
lasso_last = lm.Lasso(alpha=2, max_iter=1000)
lasso_last.fit(np.concatenate((X_train, X_val )), np.concatenate((y_train, y_val)))

# Predict sobre os dados de test
yhat_test = lasso_last.predict(X_test)

# Metrics
r2_test_lrl = np.round (r2_score (y_test, yhat_test),3)
mse_test_lrl = np.round (mean_squared_error(y_test, yhat_test), 3)
rmse_test_lrl = np.round(np.sqrt(mse_test_lrl),3)
mae_test_lrl = np.round(mean_absolute_error(y_test, yhat_test),3)
mape_test_lrl = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 test: {r2_test_lrl}, MSE test: {mse_test_lrl}, RMSE test: {rmse_test_lrl}, MAE test: {mae_test_lrl}, MAPE test: {mape_test_lrl}')

"""## Linear Regression Ridge"""

# Training the model on training data
linear_regre = LinearRegression ()
linear_regre.fit(X_train, y_train)

ridge = lm.Ridge(alpha=2, max_iter=1000)
ridge.fit(X_train, y_train)

# Predict about training data
yhat_train = ridge.predict(X_train)

# Metrics
r2_train_lrr = np.round (r2_score (y_train, yhat_train),3)
mse_train_lrr = np.round (mean_squared_error(y_train, yhat_train), 3)
rmse_train_lrr = np.round(np.sqrt(mse_train_lrr),3)
mae_train_lrr = np.round(mean_absolute_error(y_train, yhat_train),3)
mape_train_lrr = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_lrr}, MSE train: {mse_train_lrr}, RMSE train: {rmse_train_lrr}, MAE train: {mae_train_lrr}, MAPE train: {mape_train_lrr}')

# Predict about validation data
yhat_val = ridge.predict(X_val)

# Metrics
r2_val_lrr = np.round (r2_score (y_val, yhat_val),3)
mse_val_lrr = np.round (mean_squared_error(y_val, yhat_val), 3)
rmse_val_lrr = np.round(np.sqrt(mse_val_lrr),3)
mae_val_lrr = np.round(mean_absolute_error(y_val, yhat_val),3)
mape_val_lrr = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_lrr}, MSE val: {mse_val_lrr}, RMSE val: {rmse_val_lrr}, MAE val: {mae_val_lrr}, MAPE val: {mape_val_lrr}')

# Training the model on conatenated training and validation data
linear_regre_last = LinearRegression ()
linear_regre_last.fit(np.concatenate((X_train, X_val )), np.concatenate((y_train, y_val)))
ridge_last = lm.Ridge(alpha=2, max_iter=1000)
ridge_last.fit(np.concatenate((X_train, X_val )), np.concatenate((y_train, y_val)))

# Predict about test data
yhat_test = ridge_last.predict(X_test)

# Metrics
r2_test_lrr = np.round (r2_score (y_test, yhat_test),3)
mse_test_lrr = np.round (mean_squared_error(y_test, yhat_test), 3)
rmse_test_lrr = np.round(np.sqrt(mse_test_lrr),3)
mae_test_lrr = np.round(mean_absolute_error(y_test, yhat_test),3)
mape_test_lrr = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 test: {r2_test_lrr}, MSE test: {mse_test_lrr}, RMSE test: {rmse_test_lrr}, MAE test: {mae_test_lrr}, MAPE test: {mape_test_lrr}')

"""## Linear Regression Elastic Net"""

# Training the model on training data
linear_regre = LinearRegression ()
linear_regre.fit(X_train, y_train)

elastic_regre = lm.ElasticNet(alpha=2, max_iter=1000, l1_ratio=1)
elastic_regre.fit(X_train, y_train)

# Predict about training data
yhat_train = elastic_regre.predict(X_train)

# Metrics
r2_train_lren = np.round (r2_score (y_train, yhat_train),3)
mse_train_lren = np.round (mean_squared_error(y_train, yhat_train), 3)
rmse_train_lren = np.round(np.sqrt(mse_train_lren),3)
mae_train_lren = np.round(mean_absolute_error(y_train, yhat_train),3)
mape_train_lren = np.round(mean_absolute_percentage_error(y_train, yhat_train),3)
print(f'R2 train: {r2_train_lren}, MSE train: {mse_train_lren}, RMSE train: {rmse_train_lren}, MAE train: {mae_train_lren}, MAPE train: {mape_train_lren}')

# Predict about validation data
yhat_val = elastic_regre.predict(X_val)

# Metrics
r2_val_lren = np.round (r2_score (y_val, yhat_val),3)
mse_val_lren = np.round (mean_squared_error(y_val, yhat_val), 3)
rmse_val_lren = np.round(np.sqrt(mse_val_lren),3)
mae_val_lren = np.round(mean_absolute_error(y_val, yhat_val),3)
mape_val_lren = np.round(mean_absolute_percentage_error(y_val, yhat_val),3)
print(f'R2 val: {r2_val_lren}, MSE val: {mse_val_lren}, RMSE val: {rmse_val_lren}, MAE val: {mae_val_lren}, MAPE val: {mape_val_lren}')

# Training the model on conatenated training and validation data
linear_regre_last = LinearRegression ()
linear_regre_last.fit(np.concatenate((X_train, X_val )), np.concatenate((y_train, y_val)))
elastic_regre_last = lm.ElasticNet(alpha=2, max_iter=1000, l1_ratio=1)
elastic_regre_last.fit(np.concatenate((X_train, X_val )), np.concatenate((y_train, y_val)))

# Predict about test data
yhat_test = elastic_regre_last.predict(X_test)

# Metrics
r2_test_lren = np.round (r2_score (y_test, yhat_test),3)
mse_test_lren = np.round (mean_squared_error(y_test, yhat_test), 3)
rmse_test_lren = np.round(np.sqrt(mse_test_lren),3)
mae_test_lren = np.round(mean_absolute_error(y_test, yhat_test),3)
mape_test_lren = np.round(mean_absolute_percentage_error(y_test, yhat_test),3)
print(f'R2 test: {r2_test_lren}, MSE test: {mse_test_lren}, RMSE test: {rmse_test_lren}, MAE test: {mae_test_lren}, MAPE test: {mape_test_lren}')

"""## Resultados Regressão"""

# Defining lists to store training data
models = ['Random Forest', 'Decision Tree',
         'Polinomial Regression','Polinomial Regression Lasso','Polinomial Regression Ridge','Polinomial Regression Elastic Net',
         'Linear Regression','Linear Regression Lasso','Linear Regression Ridge', 'Linear Regression Elastic Net']

r2_train = [r2_train_rf, r2_train_dt, r2_train_pr, r2_train_prl, r2_train_prr, r2_train_pren, r2_train_lr, r2_train_lrl, r2_train_lrr, r2_train_lren ]
mse_train = [mse_train_rf, mse_train_dt, mse_train_pr, mse_train_prl, mse_train_prr, mse_train_pren, mse_train_lr, mse_train_lrl, mse_train_lrr, mse_train_lren]
rmse_train = [rmse_train_rf, rmse_train_dt, rmse_train_pr, rmse_train_prl, rmse_train_prr, rmse_train_pren, rmse_train_lr, rmse_train_lrl, rmse_train_lrr, rmse_train_lren]
mae_train = [mae_train_rf, mae_train_dt, mae_train_pr, mae_train_prl, mae_train_prr, mae_train_pren, mae_train_lr, mae_train_lrl, mae_train_lrr, mae_train_lren]
mape_train = [mape_train_rf, mape_train_dt, mape_train_pr, mape_train_prl, mape_train_prr, mape_train_pren, mape_train_lr, mape_train_lrl, mape_train_lrr, mape_train_lren]


# Defining lists to store validation data
models = ['Random Forest', 'Decision Tree',
         'Polinomial Regression','Polinomial Regression Lasso','Polinomial Regression Ridge','Polinomial Regression Elastic Net',
         'Linear Regression','Linear Regression Lasso','Linear Regression Ridge', 'Linear Regression Elastic Net'
]
r2_val = [r2_val_rf, r2_val_dt, r2_val_pr, r2_val_prl, r2_val_prr, r2_val_pren, r2_val_lr, r2_val_lrl, r2_val_lrr, r2_val_lren]
mse_val = [mse_val_rf, mse_val_dt, mse_val_pr, mse_val_prl, mse_val_prr, mse_val_pren, mse_val_lr, mse_val_lrl, mse_val_lrr, mse_val_lren]
rmse_val = [rmse_val_rf, rmse_val_dt, rmse_val_pr, rmse_val_prl, rmse_val_prr, rmse_val_pren, rmse_val_lr, rmse_val_lrl, rmse_val_lrr, rmse_val_lren]
mae_val = [mae_val_rf, mae_val_dt, mae_val_pr, mae_val_prl, mae_val_prr, mae_val_pren, mae_val_lr, mae_val_lrl, mae_val_lrr, mae_val_lren]
mape_val = [mape_val_rf, mape_val_dt, mape_val_pr, mape_val_prl, mape_val_prr, mape_val_pren, mape_val_lr, mape_val_lrl, mape_val_lrr, mape_val_lren]

# Defining lists to store test data
models = ['Random Forest', 'Decision Tree',
         'Polinomial Regression','Polinomial Regression Lasso','Polinomial Regression Ridge','Polinomial Regression Elastic Net',
         'Linear Regression','Linear Regression Lasso','Linear Regression Ridge', 'Linear Regression Elastic Net'
]
r2_test = [r2_test_rf, r2_test_dt, r2_test_pr, r2_test_prl, r2_test_prr, r2_test_pren, r2_test_lr, r2_test_lrl, r2_test_lrr, r2_test_lren]
mse_test = [mse_test_rf, mse_test_dt, mse_test_pr, mse_test_prl, mse_test_prr, mse_test_pren, mse_test_lr, mse_test_lrl, mse_test_lrr, mse_test_lren]
rmse_test = [rmse_test_rf, rmse_test_dt, rmse_test_pr, rmse_test_prl, rmse_test_prr, rmse_test_pren, rmse_test_lr, rmse_test_lrl, rmse_test_lrr, rmse_test_lren]
mae_test = [mae_test_rf, mae_test_dt, mae_test_pr, mae_test_prl, mae_test_prr, mae_test_pren, mae_test_lr, mae_test_lrl, mae_test_lrr, mae_test_lren]
mape_test = [mape_test_rf, mape_test_dt, mape_test_pr, mape_test_prl, mape_test_prr, mape_test_pren, mape_test_lr, mape_test_lrl, mape_test_lrr, mape_test_lren]

# Creating dictionaries
data_train_regre = {'Model': models, 'R2': r2_train, 'MSE': mse_train, 'RMSE': rmse_train, 'MAE': mae_train,  'MAPE': mape_train}
data_val_regre = {'Model': models, 'R2': r2_val, 'MSE': mse_val, 'RMSE': rmse_val, 'MAE': mae_val,  'MAPE': mape_val}
data_test_regre = {'Model': models, 'R2': r2_test, 'MSE': mse_test, 'RMSE': rmse_test, 'MAE': mae_test,  'MAPE': mape_test}

# Creating Dataframes with the results
df_train_regre = pd.DataFrame(data_train_regre)
df_val_regre = pd.DataFrame(data_val_regre)
df_test_regre = pd.DataFrame(data_test_regre)

df_train_regre

df_val_regre

df_test_regre

"""# Clusterização

## K-Means
"""

df = pd.read_csv('datasets/datasets_clusterizacao/X_dataset.csv')

df.head(175)

# Supondo que 'df' seja o seu DataFrame
x_dataset = df.values

# Plot dos clusters
plt.scatter( x_dataset[:,0], x_dataset[:,1] )

# Elbo Method ( Método do Cotovelo )
clusters = np.arange( 2, 11, 1 )
ss_list = []
for c in clusters:
  # define
  kmeans = KMeans( n_clusters=c, init='random', n_init=10, random_state=0 )
  # fit
  labels = kmeans.fit_predict( x_dataset )
  # performance
  ss_avg = mt.silhouette_score( x_dataset, labels )
  # add silhouette to list
  ss_list.append( ss_avg )

# print(ss_list)

plt.plot( clusters, ss_list, marker='o' )
plt.xlabel( 'Number of Clusters' );
plt.ylabel( 'Avergage Silhouette Score' );

# Agruapmentos
c = ss_list.index( max( ss_list ) ) + 2
print( 'Best K: {}'.format( c ) )

# define
kmeans = KMeans( n_clusters=c, init='random', n_init=10, random_state=0 )

# fit
labels = kmeans.fit_predict( x_dataset )

# performance
ss_avg = mt.silhouette_score( x_dataset, labels )
# draw figure
plt.scatter( x_dataset[:, 0], x_dataset[:, 1], c=labels )
for i in range( len( kmeans.cluster_centers_ ) ):
  plt.scatter( kmeans.cluster_centers_[i, 0],
              kmeans.cluster_centers_[i, 1],
              marker='*',
              c='orange',
              s=160 )

kmeans_model = KMeans(n_clusters=3)
kmeans_model.fit (df)

# Predict sobre os dados de treinamento
label = kmeans_model.predict (df)
# Metrics
silh_score_kmeans = np.round(silhouette_score(df, label),3)
print(f'Silhueta score: {silh_score_kmeans} \n')

# Supondo que 'df' seja o seu DataFrame
x_dataset = df.values

plt.figure(figsize=(10, 6))
plt.scatter(x_dataset[:, 0], x_dataset[:, 1], c=label, cmap='viridis')
plt.title('Clusters criados pelo Affinity Propagation')
plt.xlabel('alcohol')
plt.ylabel('malic_acid')
plt.colorbar()
plt.show()

"""## Affinity propagation"""

# Supondo que 'df' seja o seu DataFrame
x_dataset = df.values

# Plot dos clusters
plt.scatter( x_dataset[:,0], x_dataset[:,1] )

# Elbo Method ( Método do Cotovelo )
clusters = np.arange( 2, 11, 1 )
ss_list_aff = []
for c in clusters:
  # define
  model = AffinityPropagation( preference=-50)
  # fit
  labels_aff = model.fit_predict( x_dataset )
  # performance
  ss_avg = mt.silhouette_score( x_dataset, labels )
  # add silhouette to list
  ss_list_aff.append( ss_avg )

# print(ss_list)

plt.plot( clusters, ss_list_aff, marker='o' )
plt.xlabel( 'Number of Clusters' );
plt.ylabel( 'Avergage Silhouette Score' );

# Agruapmentos
c = ss_list_aff.index( max( ss_list_aff ) ) + 2
print( 'Best K: {}'.format( c ) )

# define
model = AffinityPropagation( preference=-50)

# fit
labels_aff = model.fit_predict( x_dataset )

# performance
ss_avg = mt.silhouette_score( x_dataset, labels )
# draw figure
plt.scatter( x_dataset[:, 0], x_dataset[:, 1], c=labels )
for i in range( len( kmeans.cluster_centers_ ) ):
  plt.scatter( kmeans.cluster_centers_[i, 0],
              kmeans.cluster_centers_[i, 1],
              marker='*',
              c='orange',
              s=160 )

# training model
model = AffinityPropagation( preference=-50)
model.fit( df )
# clustering data
labels_aff = model.predict( df )
# Metrics
silh_score_aff = np.round(silhouette_score(df, labels_aff),3)
print(f'Silhueta score: {silh_score_aff} \n')
# Supondo que 'df' seja o seu DataFrame
x_dataset = df.values

plt.figure(figsize=(10, 6))
plt.scatter(x_dataset[:, 0], x_dataset[:, 1], c=label, cmap='viridis')
plt.title('Clusters criados pelo Affinity Propagation')
plt.xlabel('alcohol')
plt.ylabel('malic_acid')
plt.colorbar()
plt.show()

models = ['K-means', 'Affinity propagation']
clusters = [3,3]
Silhueta_Score = [silh_score_kmeans, silh_score_aff]

# Creating dictionaries
data_clusterizacao = {'Model': models, 'Clusters': clusters, 'Silhueta_Score': Silhueta_Score}

# Creating Dataframes with the results
df_clusterizacao = pd.DataFrame(data_clusterizacao)

df_clusterizacao